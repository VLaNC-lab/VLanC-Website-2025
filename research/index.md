---
title: Research
nav:
  order: 1
  tooltip: Published works
---

<!-- # {% include icon.html icon="fa-solid fa-microscope" %}Research -->

# 🔬 Research

At the **Visual Language Neural Cognitive Computing (VLANC) Lab**, our research focuses on the intersection of artificial intelligence, cognitive science, and multimodal learning. We explore how machines can understand and integrate **language, vision, and structured knowledge** to simulate human-like cognition and reasoning.

## Key research areas include but not limited to:

<details markdown="1">
<summary>🧠 Knowledge Graphs & Reasoning </summary>
Building and utilizing domain-specific knowledge graphs for information extraction, semantic understanding, and intelligent decision-making.
</details>

<details markdown="2">
<summary>Natural Language Processing (NLP)</summary>
Investigating transformer-based models for understanding and generating human language, with applications in dialogue systems, question answering, and summarization.
</details>


<details markdown="3">
<summary>👁️ Vision-Language Integration</summary>
 Bridging visual and textual modalities using deep learning techniques for tasks such as image captioning, visual question answering (VQA), and scene understanding.
</details>
  
<details markdown="4">
<summary>🔄 Multimodal & Cognitive Computing </summary>
 Combining signals from various modalities to model human-like cognition, including memory, attention, and reasoning.
</details>

<details markdown="5">
<summary>📊Applied Machine Learning </summary>
  Designing ML and DL solutions for real-world problems in education, job skill matching, and social platforms.
</details>

Our goal is to push the boundaries of AI to create systems that can **think, learn, and interact** with the world in more human-like ways.


{% include section.html %}


## Research Papers

{% include search-box.html %}

{% include search-info.html %}

{% include list.html data="citations" component="citation" style="rich" %}
